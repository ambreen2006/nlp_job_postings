{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/postings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = None\n",
    "\n",
    "with open('data/Liveproject Resume.txt') as file_handle:\n",
    "    resume = file_handle.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_posting</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>bullets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3157fcef3ee474da_fccid.html</td>\n",
       "      <td>Data Scientist - Mountain View, CA</td>\n",
       "      <td>Data Scientist - Mountain View, CA\\nGroundTrut...</td>\n",
       "      <td>('Help senior members of the team to explore, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b423ca22a6e2c10f_fccid.html</td>\n",
       "      <td>Data Scientist - Seattle, WA</td>\n",
       "      <td>Data Scientist - Seattle, WA\\nA Bachelor or Ma...</td>\n",
       "      <td>('A Bachelor or Masters Degree in a highly qua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a559b6630c13783d_fccid.html</td>\n",
       "      <td>Junior Data Scientist - College Park, MD 20740</td>\n",
       "      <td>Junior Data Scientist - College Park, MD 20740...</td>\n",
       "      <td>('Degree: Bachelor’s degree in business analyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f579e807b5804620_fccid.html</td>\n",
       "      <td>Data Scientist - New York, NY</td>\n",
       "      <td>Data Scientist - New York, NY\\nDescription\\nDS...</td>\n",
       "      <td>('Languages: Python, PySpark, SQL', 'Data Tool...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13c9ffc0bcb07c8d_fccid.html</td>\n",
       "      <td>(Entry-Level) Data Scientist - Chicago, IL</td>\n",
       "      <td>(Entry-Level) Data Scientist - Chicago, IL\\nDa...</td>\n",
       "      <td>('Be the go-to person for Data ingest and stor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   job_posting  \\\n",
       "0  3157fcef3ee474da_fccid.html   \n",
       "1  b423ca22a6e2c10f_fccid.html   \n",
       "2  a559b6630c13783d_fccid.html   \n",
       "3  f579e807b5804620_fccid.html   \n",
       "4  13c9ffc0bcb07c8d_fccid.html   \n",
       "\n",
       "                                            title  \\\n",
       "0              Data Scientist - Mountain View, CA   \n",
       "1                    Data Scientist - Seattle, WA   \n",
       "2  Junior Data Scientist - College Park, MD 20740   \n",
       "3                   Data Scientist - New York, NY   \n",
       "4      (Entry-Level) Data Scientist - Chicago, IL   \n",
       "\n",
       "                                                body  \\\n",
       "0  Data Scientist - Mountain View, CA\\nGroundTrut...   \n",
       "1  Data Scientist - Seattle, WA\\nA Bachelor or Ma...   \n",
       "2  Junior Data Scientist - College Park, MD 20740...   \n",
       "3  Data Scientist - New York, NY\\nDescription\\nDS...   \n",
       "4  (Entry-Level) Data Scientist - Chicago, IL\\nDa...   \n",
       "\n",
       "                                             bullets  \n",
       "0  ('Help senior members of the team to explore, ...  \n",
       "1  ('A Bachelor or Masters Degree in a highly qua...  \n",
       "2  ('Degree: Bachelor’s degree in business analyt...  \n",
       "3  ('Languages: Python, PySpark, SQL', 'Data Tool...  \n",
       "4  ('Be the go-to person for Data ingest and stor...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(547, 4)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    p_text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    p_text = p_text.translate(str.maketrans('', '', string.digits))\n",
    "    p_text = unicodedata.normalize('NFKD', p_text)\\\n",
    "                        .encode('ascii', 'ignore')\\\n",
    "                        .decode('utf-8', 'ignore')\\\n",
    "                        .replace('\\n\\t', ' ')\\\n",
    "                        .replace('\\n', ' ')\\\n",
    "                        .replace('  ', ' ')\\\n",
    "                        .replace('   ', ' ')\\\n",
    "                        .rstrip()\\\n",
    "                        .lower()\n",
    "\n",
    "    p_text = ' '.join([word for word in word_tokenize(p_text) if word not in stop_words])\n",
    "    return p_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['requirements'] = df.bullets.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.requirements = df.requirements.apply(lambda x: x[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      help senior members team explore develop produ...\n",
       "1      bachelor masters degree highly quantitative fi...\n",
       "2      degree bachelors degree business analytics dat...\n",
       "3      languages python pyspark sql data tools spark ...\n",
       "4      goto person data ingest storage across cloud h...\n",
       "                             ...                        \n",
       "542    applicable degrees computer information system...\n",
       "543    experience python knowledge following numpy sc...\n",
       "544                                                     \n",
       "545    independently develop advanced analytics predi...\n",
       "546    experienced handling large data sets using sql...\n",
       "Name: requirements, Length: 547, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.requirements = df.requirements.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['help senior members team explore develop productionize optimize machine learning algorithms pipelines use hadoop spark amazon athena daily basis explore petabytes data dive deep rich set location data derive insights build product prototypes collaborate peer data scientists engineers product managers closely master degree computer science statistics mathematics engineering phd plus experience statistics machine learning fluency python significant experience sql relational databases nosql data stores familiarity open source machine learning libraries scikitlearn spark mllib experience amazon web services plus excellent communication skills'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.requirements.head(n=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿Good Student\n",
      "Data Scientist\n",
      "\t  \n",
      "\n",
      "Good Student\n",
      "123 Fake Street\n",
      "Some City, QT 12345\n",
      "123.456.7890\n",
      "no_reply@fakesite.com\n",
      "\tㅡ\n",
      "Skills\n",
      "\t  \n",
      "\n",
      "Python, Pandas, machine learning, natural language processing\n",
      "\tㅡ\n",
      "Experience\n",
      "\t  \n",
      "\n",
      "Manning / Data Analyst\n",
      "Oct 2019 - PRESENT,  REMOTE\n",
      "Analyzed and visualized vast amounts of data using Pandas, Python, and Matplotlib.\n",
      "\tㅡ\n",
      "Education\n",
      "\t  \n",
      "\n",
      "Berkeley / B.S. Mathematics\n",
      "August 2015 - May 2019,  BERKELEY, CA\n",
      "Graduated summa cum laude.\n",
      "\n",
      "\tㅡ\n",
      "Awards\n",
      "\t  \n",
      "\n",
      "Tau Beta Pi Honors Society\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_clean = clean_text(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good student data scientist good student fake street city qt noreplyfakesitecom skills python pandas machine learning natural language processing experience manning data analyst oct present remote analyzed visualized vast amounts data using pandas python matplotlib education berkeley bs mathematics august may berkeley ca graduated summa cum laude awards tau beta pi honors society\n"
     ]
    }
   ],
   "source": [
    "print(resume_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = [resume_clean] + list(df.requirements.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf_vectorizer.fit_transform(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(548, 6916)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<548x6916 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 68149 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<547x6916 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 68104 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_np_array = tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(548, 6916)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_np_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_vector = tfidf_np_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_non_zero_indicese = np.flatnonzero(resume_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 262,  276,  291,  498,  536,  622,  627,  727,  762,  925, 1411,\n",
       "       1458, 1920, 2207, 2303, 2633, 2661, 2841, 3376, 3395, 3425, 3613,\n",
       "       3669, 3722, 3732, 4055, 4183, 4255, 4432, 4597, 4767, 4829, 5015,\n",
       "       5033, 5255, 5527, 5737, 5779, 6000, 6021, 6077, 6194, 6627, 6674,\n",
       "       6741])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_non_zero_indicese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'visualized'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.get_feature_names()[6741]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_vector[439]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = tfidf_np_array @ resume_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(548,)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([312, 258, 528, 425, 398, 362, 330, 434,  84, 514, 214, 211, 357,\n",
       "       510, 207, 202, 122, 189, 183, 126, 179, 390, 345, 149,  43, 283,\n",
       "       331,  18, 308, 291, 545, 537, 208,  10, 269, 243, 540,  61, 153,\n",
       "       109, 314, 170, 154, 127, 286, 431, 396, 176, 288, 421, 499, 435,\n",
       "       192, 530, 216,  32, 132, 199, 526, 278, 428, 247, 422,  31, 203,\n",
       "       501, 474, 296, 473, 190, 493, 439, 365,  95, 488, 152, 504,  94,\n",
       "        89,  13, 295, 105, 492, 352, 250, 238, 502, 134, 478, 182,   6,\n",
       "       407, 534, 299, 417, 336, 452,  16, 517, 173, 438, 527, 316, 356,\n",
       "        67, 332,   3,  99, 271, 108, 253, 209, 523, 531, 371, 423, 244,\n",
       "       226,  42,  23, 412, 104,  49, 401, 451, 321, 342,  85, 264, 542,\n",
       "       317, 475, 338, 369, 213, 456, 197,  37, 327, 393, 280,  22, 379,\n",
       "       268, 339, 270, 267, 370, 382,  57,  38, 449, 160, 377, 521, 525,\n",
       "        46, 164, 385,  87, 381, 307,  73, 260, 430, 500,  58,  81,   8,\n",
       "       123, 470, 348,  25, 227, 375,  53, 329, 350,  50, 290, 129, 241,\n",
       "       505, 185, 212,  12,  35, 102,  27, 508, 437, 486,  76, 368, 150,\n",
       "       144, 318,  41, 112, 374,  54, 141, 110, 261, 248, 512, 347, 354,\n",
       "       358, 335,  88, 195, 468, 196, 292, 524, 145, 155,  68, 210, 441,\n",
       "       297, 380, 175, 282, 138,  20, 310,  28, 289, 259, 533, 191, 432,\n",
       "       351,  40, 131, 161, 384,  64,  44, 415,  65, 445, 411, 520,  69,\n",
       "       181, 130, 506, 515, 229, 477,  91, 404, 178, 116,  75, 546, 215,\n",
       "       496, 230, 301, 487, 306, 532,  33, 543, 225, 184, 201, 364, 394,\n",
       "       101, 443, 490, 304,  96,   1, 313, 419,  59, 147, 220, 403, 333,\n",
       "        92, 309, 373, 239, 246, 263, 363, 169, 222, 467, 168, 157,  14,\n",
       "        11, 281, 455, 414,  66, 165, 255, 293, 115, 481, 275, 221, 463,\n",
       "       273, 287, 172,  24, 346,  93,  30, 251, 188, 544, 513, 103, 522,\n",
       "         7, 355, 294,  26,   2,  36,  90, 325, 397, 343, 489, 322, 156,\n",
       "       400,  48, 472,   9, 353, 498, 148, 320, 198, 518, 427,  72, 302,\n",
       "       402, 491, 429, 535, 469, 340, 424, 458, 235, 137, 118, 323, 426,\n",
       "        70, 326, 237, 256,  39, 252,  78, 484, 121, 234, 334, 418, 442,\n",
       "       547, 254,  51, 372, 536,  98, 360, 359,  82, 151, 539, 205, 159,\n",
       "       166, 405, 315, 117, 466, 366, 420, 389, 285, 232, 444,  86, 224,\n",
       "        52,  15, 461,  62,  74,  45, 436, 163, 538, 262, 120, 142, 507,\n",
       "       483, 242, 100, 476, 392, 480,  55, 479, 433, 231,  34, 319, 453,\n",
       "       274, 257, 409, 272, 206,  83, 106, 219,   5,  60, 180, 217, 146,\n",
       "       395, 460,  29, 450, 200, 448, 305, 300, 482, 133, 337, 324, 383,\n",
       "       413, 311, 459, 391, 378, 284, 485, 465, 187,  47, 341, 410, 135,\n",
       "       223,   4, 344,  80, 388, 494, 194, 174, 236, 454, 125, 249, 177,\n",
       "       276, 124, 386, 399,  79, 516,  77, 406, 279,  97, 303, 416, 447,\n",
       "       495, 457, 298, 233, 408, 158, 186, 541, 471,  71, 128, 387, 136,\n",
       "        21, 367,  17, 228, 446,  63, 376, 519, 113, 497, 462, 440, 139,\n",
       "       143, 361, 266, 204,  19, 464, 114, 162, 511, 111, 265, 509,  56,\n",
       "       503, 349, 167, 328, 107, 193, 119, 529, 140, 245, 277, 240, 171,\n",
       "       218,   0])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(cosine_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_postings = np.argsort(cosine_similarities)[::-1][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5ad1f895aff1a7bd_fccid.html']\n"
     ]
    }
   ],
   "source": [
    "print(df[df.index == sorted_postings[0]].job_posting.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_postings[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Highest Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><head><title>Sr. Lead Data Scientist, Peacock, Direct-to-Consumer - New York, NY</title></head>\n",
       "<body><h2>Sr. Lead Data Scientist, Peacock, Direct-to-Consumer - New York, NY</h2>\n",
       "<div><div><div><div>Introducing Peacock, NBCUniversal’s new streaming service that combines timeless shows and movies, exclusive originals, kids programming and current hits, with timely news, sports and pop culture. All together. All in one app.<br/>\n",
       "<br/>\n",
       "In preparation for our launch in 2020, we are building a world-class team of smart, hungry and fearless professionals who are energized by the possibility of working at the epicenter of content, technology and culture. Join us if you would like to be a part of this exciting initiative.<br/>\n",
       "<br/>\n",
       "<b>Position Overview:</b><br/>\n",
       "<br/>\n",
       "As part of the Direct-to-Consumer Decision Sciences team, the Lead Data Scientist will be responsible for creating analytical solutions for one or more verticals of NBCU’s video streaming service including, but not limited to, the recommender system, automated marketing, personalized advertisement, commerce and revenue optimization systems, customer journey and CRM solutions.<br/>\n",
       "<br/>\n",
       "In this role, the Lead Data Scientist will use advanced data science methodologies including collaborative filtering, deep learning, reinforcement learning, on-line modeling etc. and work closely with business owners, teammates and engineers to build a state-of-the-art real-time video streaming service.<br/>\n",
       "<br/>\n",
       "<b>Responsibilities include, but are not limited to:</b><br/>\n",
       "<ul><li>\n",
       "Lead a group of data scientists in the development of analytical models using statistical, machine learning and data mining methodologies. Advise, help to resolve issues and handle non-standard cases.</li><li>\n",
       "Define procedures for cleansing, discretization, imputation, selection, generalization etc. to create high quality features for the modeling process.</li><li>\n",
       "Work with business stakeholders to define business requirements including KPI and acceptance criteria.</li><li>\n",
       "Use big data, relational and non-relational data sources to access data at the appropriate level of granularity for the needs of specific analytical projects. Maintains up to date knowledge of the relevant data set structures and participate in defining necessary upgrades and modifications.</li><li>\n",
       "Collaborate with software and data architects in building real-time and automated batch implementations of the data science solutions and integrating them into the streaming service architecture.</li><li>\n",
       "Drive work on improving the codebase and machine learning lifecycle infrastructure.</li></ul></div>\n",
       "</div><div><p><b>Qualifications/Requirements</b></p>\n",
       "<ul><li>Advanced (Master or PhD) degree with specialization in Statistics, Computer Science, Data Science, Economics, Mathematics, Operations Research or another quantitative field or equivalent.</li><li>7+ years of combined experience in advanced analytics in industry or research.</li><li>Experience in leading small teams or/and being a lead data scientist on large commercial projects.</li><li>Deep knowledge of statistical methods and machine learning with special emphasis on the advanced algorithms like neural networks, SVM, random forests, bagging, gradient boosting machines, k-means++, deep learning or reinforcement learning. Expert level in 5+ classes of algorithms.</li><li>Experience implementing scalable, distributed, and highly available systems using Google Cloud.</li><li>Experience with data visualization tools and techniques.</li><li>Understanding of algorithmic complexity of model training and testing, particularly for real-time and near real-time models.</li><li>Proficient in at least one statistical (R, Python) and one programming (Julia, Java, Scala or similar) languages.</li><li>Strong skills in data processing using SQL and PySpark.</li></ul>\n",
       "</div><div><p><b>Desired Characteristics</b></p>\n",
       "<ul><li>Working experience with commercial recommender systems or a lead role in an advanced research recommender system project.</li><li>Experience with reinforcement learning based systems.</li><li>Working experience with deep learning, particularly in the areas different form the computer vision.</li><li>Experience with multi-billion record datasets and leading projects that span the disciplines of data science and data engineering</li><li>Knowledge of enterprise-level digital analytics platforms (e.g. Adobe Analytics, Google Analytics, etc.)</li><li>Experience with television ratings and digital measurement tools (Nielsen, Rentrak, ComScore etc.)</li><li>Experience building streaming data pipelines using Kafka, Spark or Flink</li><li>Experience with large-scale video assets</li><li>Team oriented and collaborative approach with a demonstrated aptitude and willingness to learn new methods and tools</li><li>Pride and ownership in your work and confident representation of your team to other parts of NBCUniversal</li></ul>\n",
       "</div><div><p><b>Sub-Business</b></p><div>Direct-to-Consumer\n",
       "</div></div><div><p><b>Career Level</b></p>\n",
       "<div>Experienced</div>\n",
       "</div><div><p><b>City</b></p><div>New York</div>\n",
       "</div><div><p><b>State/Province</b></p>\n",
       "<div>New York\n",
       "</div></div><div><p><b>Country</b></p><div>United States\n",
       "</div></div><div><p><b>About Us</b></p>\n",
       "<div>At NBCUniversal, we believe in the talent of our people. It’s our passion and commitment to excellence that drives NBCU’s vast portfolio of brands to succeed. From broadcast and cable networks, news and sports platforms, to film, world-renowned theme parks and a diverse suite of digital properties, we take pride in all that we do and all that we represent. It’s what makes us uniquely NBCU. Here you can create the extraordinary. Join us.</div></div></div></div></body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('data/html_job_postings/'+df[df.index == sorted_postings[0]].job_posting.values[0]) as jpost:\n",
    "    display(HTML(jpost.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Lowest Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><head><title>Data Scientist - Chesterfield, MO 63017</title></head>\n",
       "<body><h2>Data Scientist - Chesterfield, MO 63017</h2>\n",
       "<h2 class=\"jobSectionHeader\"><b>Company Details<br/>\n",
       "</b></h2>\n",
       "<p></p><div><div><div><p>Midwest Employers Casualty (MEC) is a member of the W. R. Berkley Corporation, a fortune 500 company, rated A+ (Superior) by A.M. Best Company, based in Chesterfield, MO. We improve the quality of life for employees severely injured on the job and help companies understand and mitigate their risk for workers’ compensation injuries. MEC has a friendly, results-focused work environment. We seek employees who take initiative, are quick to adapt, are dependable, and like working as part of a team.</p><p></p><br/>\n",
       "<p>\n",
       "The Data Scientist role will focus on leveraging the company’s substantial data assets (as well as external data assets) to deliver actionable and meaningful business insights through predictive analytics. These efforts will focus on problems and opportunities identified by the business units (most of which will be centered on strategic objectives). Independently, the data scientist will be expected to explore data for previously unknown business related issues.<br/>\n",
       "</p><p></p><p>In order to meet these objectives, the DS will be required to perform ongoing development, training, testing and promotion of predictive models using a variety of machine learning techniques – Classification, Regression, Estimation, Time-Series Prediction, Association Rules and Simulation, etc. Similarly, the role will include the identification and utilization of data, data structures, modeling techniques, algorithms, software, and testing methodologies to best achieve the stated business objectives and assure models are performing as expected.<br/>\n",
       "</p><p></p><p>Finally, the Data Scientist will be responsible for managing progress on assigned projects and ensuring timely and accurate completion of deliverables. This will include providing progress reports to management.\n",
       "</p></div></div></div><h2 class=\"jobSectionHeader\"><b>Responsibilities\n",
       "</b></h2><div><div><div><ul><li>Take high-level project requirements and formulate timelines, milestones, and tasks as part of project execution. Provide project status reports to management regarding project progress.</li><li>\n",
       "Take business requirements from the various projects, and translate them into novel technological solutions, utilizing data and predictive analytics, ensuring that the solution meets business requirements, integrates into existing business processes, and delivers sound predictions and/or analytic output.</li><li>\n",
       "Meet with decision makers, systems owners, and end users to define business, financial, and operations requirements and systems goals, and identify and resolve systems issues.</li><li>\n",
       "Design and implement methods for the ongoing monitoring of model predictions and performance.</li><li>\n",
       "Report on prediction accuracy, model stability, and show model is operating within statistically acceptable boundaries.</li><li>\n",
       "Work alone or in conjunction with the team members to see that proper data and/or data structures are obtained for assigned projects. Identify and provide detailed documentation regarding new data and data structures. Assist in testing of new data and/or data structures.</li><li>\n",
       "Continuously explore data, data structures, modeling techniques, algorithms, software, and testing methodologies to ensure best practices are employed in modeling efforts.</li><li>\n",
       "Work with internal and external customers to assist with adoption and utilization of MEC predictive models.</li></ul>\n",
       "</div></div></div><h2 class=\"jobSectionHeader\"><b>Qualifications\n",
       "</b></h2><div><div><div><p><b>FORMAL EDUCATION &amp; CERTIFICATION</b></p><ul><li>\n",
       "Master’s degree in computer science, mathematics, statistics, engineering, physics, or other sciences.</li><li>\n",
       "Education should include significant work in advanced mathematics and/or statistics.</li></ul><p></p><br/>\n",
       "<p><b>\n",
       "KNOWLEDGE &amp; EXPERIENCE</b></p><ul><li>\n",
       "3 to 5 years of experience in related fields.</li><li>\n",
       "Excellent understanding of the organization’s goals and objectives.</li><li>\n",
       "Possess an intense curiosity and determination to explore and solve complex business problems utilizing internal/external data, technology, and scientific/statistical techniques.\n",
       "</li><li>Thorough understanding of project management practices and approaches including waterfall and Agile methodologies. Experience with project management software such as Microsoft Team Foundation Server.\n",
       "</li><li>In-depth understanding of, and practical experience with, multiple machine learning algorithms utilizing both structured and unstructured data.\n",
       "</li><li>Experience with a variety of modeling techniques including, but not limited to, Decision Trees, Naïve Bayes methods, Clustering, Regression, Neural Networks, Support Vector Machines, Markov Processes, and ensemble methods.</li><li>\n",
       "Track record of delivering valuable business-related predictive analytics solutions in a timely manner.</li><li>\n",
       "Familiarity with dimensionality reductions techniques including, but not limited to, Principal Component Analysis.\n",
       "</li><li>Thorough understanding of procedures for training, testing, and validating predictive models – oversampling, boosting, bagging, hyper-parameter optimization, classification matrices, ROC curves, n-fold cross validation, validation metrics, holdout techniques, etc.\n",
       "</li><li>Proven ability to extract meaningful insights from data.</li><li>\n",
       "History of working with very large databases for analytics purposes. This would include both transactional system data and data warehouse data.</li><li>\n",
       "Understanding of Databases and the SQL Language – SQL Server / Oracle / MySQL etc.\n",
       "</li><li>Programming languages – C++, C#, Java, Python, etc.</li><li>\n",
       "Software – SPSS, SAS, Oracle Data mining, SQL Server SSAS Data Mining, R or similar, Microsoft Office Suite – specifically Excel.</li><li>\n",
       "Experience with operating systems including Microsoft Windows and UNIX.</li><li>\n",
       "Experience with big data solutions such as Hadoop and its ecosystem.\n",
       "</li><li>Understanding of containerization software such as Docker</li><li>\n",
       "Experience with code management (version control) techniques utilizing tools such as Microsoft Team Foundation Server, Github, etc.</li></ul><div></div><br/>\n",
       "<p><b>\n",
       "PERSONAL ATTRIBUTES</b></p><ul><li>\n",
       "Excellent listening and interpersonal skills.</li><li>\n",
       "Experience working in a team-oriented, collaborative environment.</li><li>\n",
       "Ability to translate very complex subject matter into understandable written and oral communications.</li></ul><div></div><br/>\n",
       "<p><b>\n",
       "WORK CONDITIONS</b></p><ul><li>\n",
       "Occasional evening and weekend work to meet deadlines.</li><li>\n",
       "Sitting for extended periods of time.</li><li>\n",
       "Dexterity of hands and fingers to operate a computer keyboard or mouse and to handle other computer components.</li><li>\n",
       "Lifting and transporting of moderately heavy objects, such as laptop computers and reference books.</li></ul></div></div></div></body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('data/html_job_postings/'+df[df.index == sorted_postings[-1]].job_posting.values[0]) as jpost:\n",
    "    display(HTML(jpost.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
